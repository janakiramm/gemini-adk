{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11cb86a9-6667-40f4-b1c6-102df20b0bc4",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cffa0f09-a315-4642-871f-b46185ad890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a55b6-7720-4c15-aa18-b37c9a0c78c1",
   "metadata": {},
   "source": [
    "### Function Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d9d7c73-726c-4e02-a6e5-1c1229f7a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_temperature_function = {\n",
    "    \"name\": \"get_current_temperature\",\n",
    "    \"description\": \"Gets the current temperature for a given location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city name, e.g. 'San Francisco'.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7c2ac-5410-4c34-ab45-b64c4d84d6ec",
   "metadata": {},
   "source": [
    "### Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1be3bb8-b183-4a6c-94a9-927bf5685997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_temperature(location: str) -> dict:\n",
    "    \"\"\"Dummy function that returns a fixed temperature.\"\"\"\n",
    "    print(f\"Fetching temperature for {location}... (dummy function)\")\n",
    "    return {\"temperature_celsius\": 27}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4964f114-f062-487e-9e3d-e89480109f80",
   "metadata": {},
   "source": [
    "### Initialize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d083b35-8013-41c5-8307-8007be7773a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "tools = types.Tool(function_declarations=[get_temperature_function])\n",
    "config = types.GenerateContentConfig(tools=[tools])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aff00d2-6b70-4aac-bf59-d476ec59e478",
   "metadata": {},
   "source": [
    "### Send the User Message (Turn 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9945b739-2232-4e1b-80b0-b8c6e7c60b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = types.Content(role=\"user\", parts=[types.Part(text=\"What's the temperature in London?\")])\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[user_message],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88701a23-306c-48c6-875b-c076e79e8c36",
   "metadata": {},
   "source": [
    "### Extract, Invoke the Function Call and Pass Response (Turn 2 & 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fc130-3c67-4434-bfea-b4d0059d1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_call = response.candidates[0].content.parts[0].function_call\n",
    "\n",
    "if function_call:\n",
    "    print(f\"Function to call: {function_call.name}\")\n",
    "    print(f\"Arguments: {function_call.args}\")\n",
    "\n",
    "    # Call the backend function manually\n",
    "    function_result = get_current_temperature(**function_call.args)\n",
    "    print(f\"Function result: {function_result}\")\n",
    "\n",
    "    # Build the function call content (as Gemini generated it)\n",
    "    model_function_call = types.Content(\n",
    "        role=\"model\",\n",
    "        parts=[types.Part(function_call=function_call)]\n",
    "    )\n",
    "\n",
    "    # Build the function response content\n",
    "    function_response_content = types.Content(\n",
    "        role=\"function\",\n",
    "        parts=[types.Part(function_response=types.FunctionResponse(\n",
    "            name=function_call.name,\n",
    "            response=function_result\n",
    "        ))]\n",
    "    )\n",
    "\n",
    "    follow_up_response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=[\n",
    "            user_message,             # Turn 1: User\n",
    "            model_function_call,      # Turn 2: Model's function call\n",
    "            function_response_content # Turn 3: Function response\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    final_text = follow_up_response.candidates[0].content.parts[0].text\n",
    "    print(f\"\\nGemini's final response: {final_text}\")\n",
    "\n",
    "else:\n",
    "    print(\"No function call found in the response.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
